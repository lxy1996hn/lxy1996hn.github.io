<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    hostname: new URL('http://yoursite.com').hostname,
    root: '/',
    scheme: 'Gemini',
    version: '7.7.0',
    exturl: false,
    sidebar: {"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    comments: {"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: '',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}
  };
</script>

  <meta property="og:type" content="website">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://yoursite.com/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: true,
    isPost: false
  };
</script>

  <title>Hexo</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Hexo</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>Home</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>Archives</a>

  </li>
  </ul>

</nav>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/04/30/IIS-lecture-MAS-PART1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Author">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/04/30/IIS-lecture-MAS-PART1/" class="post-title-link" itemprop="url">IIS lecture MAS PART1</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2020-04-30 15:25:05 / Modified: 20:01:53" itemprop="dateCreated datePublished" datetime="2020-04-30T15:25:05+01:00">2020-04-30</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="trends-in-computing"><a href="#trends-in-computing" class="headerlink" title="trends in computing"></a>trends in computing</h3><h2 id="informal-definition"><a href="#informal-definition" class="headerlink" title="informal definition"></a>informal definition</h2><h2 id="understanding-the-problem"><a href="#understanding-the-problem" class="headerlink" title="understanding the problem"></a>understanding the problem</h2><h2 id="Applications"><a href="#Applications" class="headerlink" title="Applications"></a>Applications</h2>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/04/30/IIS-Lecture5-semantic-network/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Author">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/04/30/IIS-Lecture5-semantic-network/" class="post-title-link" itemprop="url">IIS Lecture5 semantic network</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2020-04-30 15:14:14 / Modified: 19:54:00" itemprop="dateCreated datePublished" datetime="2020-04-30T15:14:14+01:00">2020-04-30</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="semantic-network"><a href="#semantic-network" class="headerlink" title="semantic network"></a>semantic network</h1><p>表示知识有很多种方式，比如logic，比如semantic network。 比如 structure representation</p>
<h2 id="what-is-semantic-network"><a href="#what-is-semantic-network" class="headerlink" title="what is semantic network"></a>what is semantic network</h2><p>Definition：<strong>Semantic network</strong> is a simple representation scheme which uses a graph of <strong>labelled nodes</strong> and <strong>labelled directed arcs</strong> to encode knowledge。 </p>
<ul>
<li><em>Nodes</em>-objects, concepts,events, attributes</li>
<li><em>Arcs</em>- relationship between nodes representing attributes of their relationship </li>
<li></li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/04/30/IIS-lecture4-incosistency/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Author">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/04/30/IIS-lecture4-incosistency/" class="post-title-link" itemprop="url">IIS lecture4 inconsistency</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2020-04-30 14:05:44 / Modified: 20:03:54" itemprop="dateCreated datePublished" datetime="2020-04-30T14:05:44+01:00">2020-04-30</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="what-is-inconsistency"><a href="#what-is-inconsistency" class="headerlink" title="what is inconsistency"></a>what is inconsistency</h2><p>if every model of K is also a model of $\beta$ then K entails $\beta$ </p>
<p><strong>definition</strong>: GIven a knowledge base K, if there exists a sentence $\beta$ such that K <strong>Ⱶ</strong> $\beta$ and <strong>K</strong> <strong>Ⱶ</strong> <strong>¬</strong> <strong>β</strong> then K is said inconsistent. </p>
<p><strong>definition: </strong> <strong>K is inconsistent if</strong> <strong>K has no models*</strong>, or<em> <strong>K</strong> <em>*Ⱶ ┴ (┴ means false)</em></em>.</p>
<p>normal practice: integrity constraints the condition must be satisfied. </p>
<p>example: <em>Tom takes his umbrella when raining; he either drives or walks to work depending on the weather; he teaches on some days</em></p>
<p>atoms:{take umbralla, drive to work,raining, teach}</p>
<p>没有walk是因为walk是drive的反方向</p>
<p>possible world： 4*4=16</p>
<p>Knowledge base{Tom teaches today}</p>
<p>I ={Tom does not walk to work when teaching } a=teach, b=drive to work. </p>
<p>K union I {a,a-&gt;b}</p>
<p><em>w_1={<strong>¬</strong>take-umbrella, drive to work,</em> <em>¬<strong>teach, raining} = {</strong>¬**c, b,</em> <em>¬**a, d}</em> 不是。 因为不能使得 every sentence in K union I.</p>
<h2 id="Consistency"><a href="#Consistency" class="headerlink" title="Consistency"></a>Consistency</h2><p>Con（K)={S is a subset of K |<em>S Ⱶ</em> <em>¬</em> <em>┴</em>)</p>
<p>: <em>K = {a, a</em> <em>à</em> <em>¬</em> <em>b}, then T={a} is a consistent subset of K, T’={a</em> <em>à</em> <em>¬</em> <em>b} is another consistent subset of K.</em></p>
<h2 id="maximal-consistent-subsets："><a href="#maximal-consistent-subsets：" class="headerlink" title="maximal consistent subsets："></a>maximal consistent subsets：</h2><p>MC(K)={</p>
<h3 id="definition-of-Inconsistent-subsets"><a href="#definition-of-Inconsistent-subsets" class="headerlink" title="definition of Inconsistent subsets"></a>definition of Inconsistent subsets</h3><h2 id="Measuring-inconsistency-in-knowledge-base"><a href="#Measuring-inconsistency-in-knowledge-base" class="headerlink" title="Measuring inconsistency in knowledge base"></a>Measuring inconsistency in knowledge base</h2><h3 id="Drastic-inconsistency-measure-I-d："><a href="#Drastic-inconsistency-measure-I-d：" class="headerlink" title="Drastic inconsistency measure I_d："></a>Drastic inconsistency measure I_d：</h3><p>it says that a knowledge base K is either good or bad </p>
<h3 id="Minimal-inconsistent-subset-based-measure"><a href="#Minimal-inconsistent-subset-based-measure" class="headerlink" title="Minimal inconsistent subset based measure"></a>Minimal inconsistent subset based measure</h3><p>it counts how many <strong>minimal inconsistent subsets that K contains.</strong> The more, the worse, implying more inconsistent information.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/04/27/IAI-search/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Author">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/04/27/IAI-search/" class="post-title-link" itemprop="url">IAI search </a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-04-27 11:50:13" itemprop="dateCreated datePublished" datetime="2020-04-27T11:50:13+01:00">2020-04-27</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-04-30 19:54:11" itemprop="dateModified" datetime="2020-04-30T19:54:11+01:00">2020-04-30</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="什么是Search-problem"><a href="#什么是Search-problem" class="headerlink" title="什么是Search problem"></a>什么是Search problem</h2><p><img src="C:\Users\32027\AppData\Roaming\Typora\typora-user-images\image-20200427115849707.png" alt="image-20200427115849707"></p>
<p>search is about <strong>how a sequence if action that achieves a goal</strong> when no single action will do.</p>
<p>相比于machine learning 给出single action， search 解决的是如何产生一整个action sequence。 </p>
<p>可不可以理解为machine learning中大多的特征我们是把他们抽象为没有关系的量。或者说 independent variable。 那么search就是有相关关系的量，比如怎么处理大象分两步，1. 打开冰箱，2.放进大象。 怎量不是不能分开的。</p>
<h3 id="application"><a href="#application" class="headerlink" title="application"></a>application</h3><ul>
<li><p>route finding actions： leave station objective： fewest changes</p>
<p>这里面包含了大量的action，先怎么走，再怎么走。</p>
</li>
<li><p>solving puzzle actions： move pieces objectives： reach a certain configuration</p>
</li>
<li>robot planning actions: translate and rotate joints objective: faster? </li>
<li><p>speech recognition </p>
</li>
<li><p>action</p>
</li>
<li><p>objectives</p>
</li>
</ul>
<h2 id="Tree-search-Monte-Carlo-tree-search"><a href="#Tree-search-Monte-Carlo-tree-search" class="headerlink" title="Tree search(Monte Carlo tree search )"></a>Tree search(Monte Carlo tree search )</h2><h3 id="search-problem"><a href="#search-problem" class="headerlink" title="search problem"></a>search problem</h3><p>search 的核心是将非常复杂的问题分解为简单的问题，分解成每一不做什么，不作甚么，以及相应的后果但这样的问题是如果想要找到最好的就需要遍历$2^n$那样就太过麻烦了。所以search problem 引入了state。通过选择state 来找到有效的polynomial time algorithms。 什么是state</p>
<p>search algorithms require a structure to keep track of the search tree that is being constructed</p>
<h3 id="search-tree"><a href="#search-tree" class="headerlink" title="search tree"></a>search tree</h3><p><img src="C:\Users\32027\AppData\Roaming\Typora\typora-user-images\image-20200427125248587.png" alt="image-20200427125248587"></p>
<p>they usually contain：</p>
<blockquote>
<p>$S_{start}:$ starting points  the root of the tree</p>
<p>Actions(s): possible actions: each edge leaving a node s corresponds to a possible action a that could performed in state s.  </p>
<p>Cost(s,a): action cost leaving node s through action a</p>
<p>Succ(s,a): successors</p>
<p>Goal(s): found solutions: leaves </p>
</blockquote>
<p>core: to find the root to leaf  path that has the minimum cost. </p>
<h3 id="Measuring-performance"><a href="#Measuring-performance" class="headerlink" title="Measuring performance"></a>Measuring performance</h3><ul>
<li><p>completeness</p>
<p>is the algorithms guaranteed to find a solution when there is one</p>
<p><em>b</em>: THE BRANCHING factor or maximum number of successors of any nodes;有多少个成功了</p>
<p><em>d</em>: the depth of shallowest node （the numbers of steps along the path to root）（有多少步，infinite？）（有多少的分支）</p>
<p><em>D</em> the length of any path，</p>
</li>
<li><p>optimality </p>
<p>Does the strategy find the optimal solution </p>
</li>
<li><p>Time complexity </p>
<p>How long does it take to find a solution</p>
</li>
<li><p>space complexity </p>
<p>How much memory is needed to perform the search </p>
</li>
</ul>
<h3 id="backtracking-search"><a href="#backtracking-search" class="headerlink" title="backtracking search"></a>backtracking search</h3><p>回溯法又称择优搜索法。按选优条件向前搜索以达到目的。当探索到某一步发现达不到目标就退回重选</p>
<p>backtracking search is the simplest algorithm which just tries all paths。</p>
<p><img src="C:\Users\32027\AppData\Roaming\Typora\typora-user-images\image-20200427132623116.png" alt="image-20200427132623116"></p>
<p>回溯法是通过调用所有可能的path，如果调用的这个path有我们需要的结果（最优而不仅是成功）那么达成目标，继续考虑其他的。没有的话，那么考虑其他的分支，先从深度考虑开始。就是现在这个node往下面还能走到哪。走不下不就往回跳。backtracking 的时间与nodes成比例，所以耗时会越来越久。一般的解决方法就是之抓取最大的depth在某些点放弃或者比允许visit same state</p>
<h3 id="Depth-first-search-（DFS）（last-in-first-out）（stack）"><a href="#Depth-first-search-（DFS）（last-in-first-out）（stack）" class="headerlink" title="Depth first search （DFS）（last in first out）（stack）"></a>Depth first search （DFS）（last in first out）（stack）</h3><p>Idea： Backtracking search +stop when find the first goal state,不track cost</p>
<p>Assumption： Action cost Cost(s,a)=0</p>
<p>和backtracking search 的区别在于当找到最优解。就停止。 </p>
<p>Memory：O(D)(small)</p>
<p>Time： $O(b^D)$ 最坏的情况</p>
<h3 id="breadth-first-search-（first-in-first-out）-queue"><a href="#breadth-first-search-（first-in-first-out）-queue" class="headerlink" title="breadth first search （first in first out）(queue)"></a>breadth first search （first in first out）(queue)</h3><p>Idea： explore <strong>all nodes</strong> in order of increasing depth</p>
<p>assumption； Action cost Cost（s，a）=c</p>
<p>Memeory： $O(b^d)$(worse)</p>
<p>Time: $O(b^d)$</p>
<h3 id="DFS-with-iterative-deepening"><a href="#DFS-with-iterative-deepening" class="headerlink" title="DFS with iterative deepening"></a>DFS with iterative deepening</h3><p>Idea: Modify DFS to stop at a maximum depth</p>
<p>Idea: call DFS for maximum depth </p>
<p>Memory: O(d) (better) </p>
<p>Time: O(b d ) (same as BFS)</p>
<p><img src="https://pic3.zhimg.com/v2-5189bbfc3914357792fc1973e49c1376_b.webp" alt="img"></p>
<p><img src="C:\Users\32027\AppData\Roaming\Typora\typora-user-images\image-20200427220411876.png" alt="image-20200427220411876"></p>
<p>在memory space与时间的较量中，memory space 胜出因为memory space 是有限的</p>
<h2 id="dynamic-programming"><a href="#dynamic-programming" class="headerlink" title="dynamic programming"></a>dynamic programming</h2><p>dynamic programming 的核心在于利用历史记录来避免重复计算</p>
<h3 id="what-is-future-cost"><a href="#what-is-future-cost" class="headerlink" title="what is future cost"></a>what is future cost</h3><p> the cost of minimum path from s to a. </p>
<h3 id="action"><a href="#action" class="headerlink" title="action"></a>action</h3><p>from s—&gt;a have to pass s’ and for s’ the future path is minimum s’</p>
<p>很多的state的效果是一样的，比如我先从家出门去小卖部，和先从家出门去小卖部中间的点再去小卖部是一样的？</p>
<p>assumption:  the state graph defined by Actions(s) and Succ(s,a) is acylic</p>
<p><img src="C:\Users\32027\AppData\Roaming\Typora\typora-user-images\image-20200427223051948.png" alt="image-20200427223051948"></p>
<h3 id="算法步骤"><a href="#算法步骤" class="headerlink" title="算法步骤"></a>算法步骤</h3><ol>
<li>定义数组元素： 定义一个数组用来保存历史</li>
<li>找出数组元素之间的关系式 </li>
<li>找出初始值。就是不能不能分割的值比如f（0）和f（1）</li>
</ol>
<h2 id="uniform-Cost-search"><a href="#uniform-Cost-search" class="headerlink" title="uniform Cost search"></a>uniform Cost search</h2><h2 id="informed-vs-uninformed-search"><a href="#informed-vs-uninformed-search" class="headerlink" title="informed vs uninformed search"></a>informed vs uninformed search</h2><h2 id="Greedy-search"><a href="#Greedy-search" class="headerlink" title="Greedy search"></a>Greedy search</h2><h2 id="A-search-algorithms"><a href="#A-search-algorithms" class="headerlink" title="A* search algorithms"></a>A* search algorithms</h2><h2 id="Heuristics-search-algorithms"><a href="#Heuristics-search-algorithms" class="headerlink" title="Heuristics search algorithms"></a>Heuristics search algorithms</h2><h2 id="Relaxation"><a href="#Relaxation" class="headerlink" title="Relaxation"></a>Relaxation</h2>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/04/26/IAI-Neural-Network/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Author">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/04/26/IAI-Neural-Network/" class="post-title-link" itemprop="url">IAI Neural Network</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-04-26 18:14:38" itemprop="dateCreated datePublished" datetime="2020-04-26T18:14:38+01:00">2020-04-26</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-04-30 20:03:37" itemprop="dateModified" datetime="2020-04-30T20:03:37+01:00">2020-04-30</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Neural-Networks"><a href="#Neural-Networks" class="headerlink" title="Neural Networks"></a>Neural Networks</h1><p><a href="https://www.cnblogs.com/subconscious/p/5058741.html" target="_blank" rel="noopener">神经网络</a></p>
<p>所有算法的黑心都在于matrix的计算。以及导数</p>
<h2 id="什么是-neural-network"><a href="#什么是-neural-network" class="headerlink" title="什么是 neural network"></a>什么是 neural network</h2><p>神经网络是科学家通过对神经的模拟得出的一种算法。他一般来说包括三个方面。</p>
<ul>
<li>输入层： 所有的信号</li>
<li>隐藏层</li>
<li>输出层</li>
</ul>
<h2 id="什么是神经元模型。"><a href="#什么是神经元模型。" class="headerlink" title="什么是神经元模型。"></a>什么是神经元模型。</h2><p>神经元模型是一个包含输入，输出，计算功能的模型，输入可以类比为神经元的树突，输出就是神经元的轴突。计算就是细胞核。</p>
<p><img src="https://images2015.cnblogs.com/blog/673793/201512/673793-20151219153856802-307732621.jpg" alt="神经网络"></p>
<p>连接是神经元中最重要的东西，每一个连接都有一个权重。这个可以理解为当人在受到相同的input的时候为什么会表现不同，这很可能是因为对于每个input来说的权重都是不同的。而神经网络训练算法的核心就是盐巴权重调整到最佳。经过连接后的信号就会变成$a*w$ a是input，w是权重</p>
<p>那么output就是Z，$z=G(a_1<em>w_!+a_2</em>w_2…..)$</p>
<p>G函数就是active function。 有时候就是sgn函数</p>
<p>比如$\phi(x)=e^{\beta x}-1\over{e^{\beta x}+1}$</p>
<h2 id="神经网络的类别"><a href="#神经网络的类别" class="headerlink" title="神经网络的类别"></a>神经网络的类别</h2><ol>
<li><p>单个神经网络</p>
<p>在感知器中主要有输入层和输出层，输入层负责信息传输，输出层负责对前面的输入进行计算。那么拥有一个计算层的网络就是<em>单层神经网络</em>，多层的就是多层神经网络。 如果要预测的不是值而是向量那么就是</p>
</li>
</ol>
<p><img src="https://images2015.cnblogs.com/blog/673793/201512/673793-20151230204223917-579926148.jpg" alt="img"></p>
<p>​                            $g(w*a)=z$</p>
<p>记住$W1,2$表示的是后一层的第一个神经元与第一层的第二个神经元相连，也就是说是后面的在前面，前面的在后面。 </p>
<p>但是这种算法有很致命的缺点就是不能处理处理xor </p>
<p><img src="C:\Users\32027\AppData\Roaming\Typora\typora-user-images\image-20200426220758746.png" alt="image-20200426220758746"></p>
<h2 id="BP-算法"><a href="#BP-算法" class="headerlink" title="BP 算法"></a>BP 算法</h2><p>BP算法通过增加了一个计算层的方式解决了计算太过复杂起的问题。它采用的方法就是则只能加一个隐藏层。由input经过加权得到的不是Z而是a。然后由a在进行一次神经网络得到最后的结果。</p>
<p><img src="https://images2015.cnblogs.com/blog/673793/201512/673793-20151222164731249-360921014.jpg" alt="img"></p>
<p>偏置节点：只是存储功能，而且存储值为一</p>
<h2 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h2><p>神经网络的目的就是要使所有的训练数据的损失尽可能的小。 换句话就是要</p>
<p>$loss=(y_p -y)^2$</p>
<p>导数方法不能采用的原因在于，即使求导后的值还是太过复杂，所以我们采用梯度下降的方法，每隔一段求一下梯度，直到梯度近似为0，可是这样的方法还是有弊病，所有有时候我们会使用BP。</p>
<h2 id="梯度下降法"><a href="#梯度下降法" class="headerlink" title="梯度下降法"></a>梯度下降法</h2><p>梯度下降法是通过一段一段的下降来得到最小值，想象一下这样的一个情景，小胡是一个盗墓贼，有一次他被困在山里了，如果盲目的绕路，就会迷失方向，所有他需要找一条能够最快到山脚的路。那么根据梯度下降法，他需要做的很简单就是，找出目前这个方向最陡峭方向，沿着这个方向（梯度的相反方向）走。在数学上梯度就是这个函数变化最快的方向。</p>
<p>在数学上，对于梯度的定义可以简单的概括为这个关系式对每一个相关的变量求导最后形成的向量，比如</p>
<script type="math/tex; mode=display">
{\partial\over{\partial x}}(x^2 y^2)=2xy^2\\
{\partial\over{\partial y}}(x^2 y^2)=2x^2y\\
<2xy^2,2x^2y></script><p>那么对于每一步就是</p>
<p>​                                 $\theta^1 =\theta^0 -\alpha \nabla J(\theta)$</p>
<h2 id="损失函数以及梯度下降法"><a href="#损失函数以及梯度下降法" class="headerlink" title="损失函数以及梯度下降法"></a>损失函数以及梯度下降法</h2><p>对于神经网络来说错误就是$E^\mu =1/2 (y^u -o^u）^2$</p>
<p>我们要做的就是找到合适的$w$ 能够减低$E^u$ 以及</p>
<p>E实际上是$E=\sum_u E^u$ 对于E 总共有K个w影响。</p>
<p>​                                   ${\partial E\over \partial w} ={\partial\over w}\sum E^u=\sum_u {\partial E^u\over \partial w_j} $</p>
<script type="math/tex; mode=display">
{\partial E^u\over \partial w_j} ={\partial E^u\over \partial o^u}*{\partial o^u\over \partial w^u}</script><script type="math/tex; mode=display">
{\partial E^u\over \partial o_u} =-(y^u-o^u)</script><script type="math/tex; mode=display">
{\partial o^u\over \partial w_j} =\phi'(\sum^k_{i=1}w_ix^u_i)x^u_</script><h2 id="Gradient-Descent-for-multiple-Outputs"><a href="#Gradient-Descent-for-multiple-Outputs" class="headerlink" title="Gradient Descent for multiple Outputs"></a>Gradient Descent for multiple Outputs</h2><p><img src="C:\Users\32027\AppData\Roaming\Typora\typora-user-images\image-20200427112438245.png" alt="image-20200427112438245"></p>
<h2 id="Capabilities-of-multi-layer-NNs"><a href="#Capabilities-of-multi-layer-NNs" class="headerlink" title="Capabilities of multi-layer NNs"></a>Capabilities of multi-layer NNs</h2><p>Kolmogorov theorem:  Any continuous function can be implemented by a neural network with one hidden layer and n inputs, 2n+1 nodes in the hidden layer and an arbitrary number of nodes in the output layer. </p>
<h2 id="BP-算法解析"><a href="#BP-算法解析" class="headerlink" title="BP 算法解析"></a>BP 算法解析</h2><p><a href="[https://www.zhihu.com/search?type=content&amp;q=Back%20Propagation](https://www.zhihu.com/search?type=content&amp;q=Back Propagation">BP算法解析</a>)</p>
<p>BP 算法的核心是gradient descent 和partial derivative。 gradient descent是解决所有network的方法，partial derivative 是在多层运算复杂的情况的解决方案</p>
<p>BP算法的步骤</p>
<ol>
<li><p>求出 feed forward pass。  即$1/2(y-o)^2$</p>
</li>
<li><p>求出backward pass</p>
<p>2.1 首先更新output层对于中间层的W关系</p>
</li>
</ol>
<p>   2.2 更新中间层对于输入层的w的关系</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/04/19/lecture5-decision-tree/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Author">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/04/19/lecture5-decision-tree/" class="post-title-link" itemprop="url">lecture5 decision tree </a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-04-19 18:00:16" itemprop="dateCreated datePublished" datetime="2020-04-19T18:00:16+01:00">2020-04-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-04-30 20:00:29" itemprop="dateModified" datetime="2020-04-30T20:00:29+01:00">2020-04-30</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="decision-tree"><a href="#decision-tree" class="headerlink" title="decision tree"></a>decision tree</h1><h3 id="什么是pattern"><a href="#什么是pattern" class="headerlink" title="什么是pattern"></a>什么是pattern</h3><p>所谓的pattern应该就是指的每一个data</p>
<h2 id="什么是decision-tree以及decision-tree的作用是什么"><a href="#什么是decision-tree以及decision-tree的作用是什么" class="headerlink" title="什么是decision tree以及decision tree的作用是什么"></a>什么是decision tree以及decision tree的作用是什么</h2><p>所谓的decision tree就是如何构造一个feature之间的关系，使得可以通过feature与feature的连接来得到最后的target。 用另一句话说就是决策树，和classifier不同，classifier并不会对如何建立features之间的联系来得到decision tree进行描述。</p>
<p>对于decision tree大概有三种常用的方法： </p>
<ol>
<li>信息增益(information gain)</li>
</ol>
<ol>
<li><p>增益比率(gain ratio)</p>
</li>
<li><p>基尼不纯度(Gini impurity)</p>
</li>
</ol>
<p>课本上说决定decision tree的是在他们所处的node上的纯洁性purity。 我的理解是如何能把他们划分的更好，能以少量的branch将所有的pattern划分进去。而选择不同的features作为分叉树的开端都会导致不同的结果。</p>
<h2 id="什么是信息（如何衡量一句话有多废）"><a href="#什么是信息（如何衡量一句话有多废）" class="headerlink" title="什么是信息（如何衡量一句话有多废）"></a>什么是信息（如何衡量一句话有多废）</h2><p><a href="https://mp.weixin.qq.com/s?__biz=MzI1OTYwNDE2Mg==&amp;mid=2247483753&amp;idx=1&amp;sn=acec759cf688e21660b61e791986bfac&amp;chksm=ea772ac4dd00a3d239995c8e6b9e83159e1ddd35781ec2109e1e0b6678f088001d988ca5756f&amp;token=47119943&amp;lang=zh_CN#rd" target="_blank" rel="noopener">如何衡量一句话有多废</a></p>
<p>首先对于废话的定义就是没有什么信息含量的话，比如我说太阳会从东方升起，这句话没有信息含量，但如果说太阳会从西边升起，也没有因为，太阳一般是不可能从西边升起的。 信息量代表着在多大程度上这个信息能够帮助你的决策。 </p>
<p>但如何衡量一句话到底有多废，entropy 的前提就是认为<strong>不确定程度</strong>与概<strong>率分布</strong>有关。注意是概率分布。即 概率分布越平均，不确定程度越大。 注意这里隐含的一个信息是classification是处在两种或者多种情况，你需要根据信息来判断属于那种情况，所以这里的概率都是指的那种情况的概率。在<a href="https://mp.weixin.qq.com/s?__biz=MzI1OTYwNDE2Mg==&amp;mid=2247483753&amp;idx=1&amp;sn=acec759cf688e21660b61e791986bfac&amp;chksm=ea772ac4dd00a3d239995c8e6b9e83159e1ddd35781ec2109e1e0b6678f088001d988ca5756f&amp;token=47119943&amp;lang=zh_CN#rd" target="_blank" rel="noopener">如何衡量一句话有多废</a> 给出了一个例子。假设一个电影院有215个座位，那么小明有可能坐在任何一个位置上。这个时候<strong>不确定程度很大</strong>。这个时候如果给出一个<strong>信息</strong>： 小明坐在第一排的任何任何一个位置的概率就缩小了，或者说现在是新的概率分布了。也生成了<strong>新的不确定程度</strong> 那么<strong>信息量就是就两个不确定程度相减。</strong>也就是给出的这个信息能在多大程度上改变entropy。     </p>
<p>为了量化这些量，对数函数$-log$被引入了。-log具有的特性为可以保证一概率为幂的对数函数为整数。 而且两个独立事件（或者说feature。不同feature的选项）A和B消除的不确定性 就是相减：$-log(p(x1)*p(x2))=-log(p(x1))-log(p(x2))$ </p>
<p>由此，我们可以定义一个概率分布的不确定性： </p>
<script type="math/tex; mode=display">
H=\sum^n_{i=1}-p_i log_2 (p_i)</script><h3 id="什么是purity"><a href="#什么是purity" class="headerlink" title="什么是purity"></a>什么是purity</h3><p>pure：they will contain only data of one class(换句话说不能再往下分)</p>
<p>impurity： 如果他包含了来自其他class的数据。</p>
<p>decision tree 就是要去能够带来最纯洁的features 的<strong>排列方式</strong></p>
<h3 id="如何测量-purity"><a href="#如何测量-purity" class="headerlink" title="如何测量 purity"></a>如何测量 purity</h3><p>对于测量purity的方法，我们可以采用entropy(信息熵)。信息熵就是所有样本各种样本出现的不确定之和。如果信息熵越大，那么不确定就越大，把信息弄清楚需要的信息量就越多。信息熵越大，那么这个属性所拥有的样本类别越大 entropy 测量的information content或者说（lack of information）of a probability distribution </p>
<p>假设我们有n 个class。$P_i$是 probability 当 patterns 属于class i的时候</p>
<p>the entropy of this distribution is given by</p>
<p>​    </p>
<script type="math/tex; mode=display">
H=\sum^n_{i=1}-p_i log_2 (p_i)</script><p>注意是所有class的$-p_i log_2 (p_i)$ 之和。 </p>
<p><img src="C:\Users\32027\AppData\Roaming\Typora\typora-user-images\image-20200420092159182.png" alt="image-20200420092159182"></p>
<p>information gain：根据<a href="https://zhuanlan.zhihu.com/p/41134986" target="_blank" rel="noopener">信息熵</a> 的说法： 特征A 对训练数据集D的信息增益g(D,a),定义为集合D的经验熵 H(D) 与特征A 给定条件下D的经验条件熵H(D|A)之差</p>
<p>​            </p>
<script type="math/tex; mode=display">
Gain(X)=info（D）-info_A(D)</script><h3 id="信息熵与classification-的关系"><a href="#信息熵与classification-的关系" class="headerlink" title="信息熵与classification 的关系"></a>信息熵与classification 的关系</h3><p>特征A 对训练数据集D的信息增益$g(D,A)$ 定义为集合D的经验熵H(D) 与特征A 在给定条件下D的经验条件熵H(D|A)之差，即</p>
<script type="math/tex; mode=display">
g(D,A)=H(D)-H(D|A)</script><p>决策树学习英勇信息增益准则作为选择特征，给定训练数据集D和特征A。经验熵 H(D|A)表示特征A给给定条件下对数据集D进行分类的不确定性。差即为信息增益，就表示由于特征A而使得对数据集D的分类的不确定较少的程度因为不同的特征具有不同的信息增熵。所有信息增熵具有更强的分类能力</p>
<p>这段话说的假设，我们有一个比如说生病那么对于最终的得病的结果来说就有两种，一种是得病，一种是没得，这种情况下不确定的程度是很高的。$H(D)=-1/2log_2(1/2)-1/2log_2(1/2)$ 当然这种前提是按照得病和没得病的个数都是1/2 来算的。如果不是这样，会有差别。具体参见<a href="https://zhuanlan.zhihu.com/p/41134986" target="_blank" rel="noopener">信息熵</a></p>
<h2 id="pruning-Decision-tree（剪枝）"><a href="#pruning-Decision-tree（剪枝）" class="headerlink" title="pruning Decision tree（剪枝）"></a>pruning Decision tree（剪枝）</h2><h3 id="为什么要剪枝"><a href="#为什么要剪枝" class="headerlink" title="为什么要剪枝"></a>为什么要剪枝</h3><p>随着决策树的增长，训练集上的精度是单调上升的，然而在独立的测试样例张测出来的精度是先上升后下降。这是由于噪音，错误的样本数据。比如说被进行了错误的判断。特征属性不能完全作为分类标准，或者数据量不够大导致的。所以我们就需要剪枝来帮助我们。这也就是剪枝的作用是帮助generalisation。<a href="https://www.cnblogs.com/starfire86/p/5749334.html" target="_blank" rel="noopener">剪枝</a></p>
<p>剪枝有两种预剪枝和后剪枝。</p>
<p>预剪枝是在完全正确分类训练集之前，就停止输的生长，</p>
<ol>
<li><p>比如达到一定高度，</p>
</li>
<li><p>达到某一个节点的示例具备相同的特征向量，</p>
</li>
<li>定义一个阈值，当某个节点的示例个数小于阈值就停止生长</li>
</ol>
<p>后剪枝(postpruning):是首先构造完整的决策树，运输树过度拟合。然后对于置信度不够的子树用叶子节点替代. 这种方法更常用</p>
<p>参考<a href="http://www.cse.unsw.edu.au/~cs9417ml/DT2/pruning.html" target="_blank" rel="noopener">pruning</a></p>
<p>lecture notes 讲述的是MEP(minimum error pruning),其思路是采用自底向上，对于书中每个非叶节点，计算该节点的误差error，然后计算该节点每个分支的误差，加权相加。权为每个分支拥有的训练样本的比例。如果Er(t)&gt;Er(T就保留概述</p>
<p>举例 比如假设 队友node i 总共有k 个pattern 还有 c&gt;k/2</p>
<h2 id="如何构造属于自己decision-tree"><a href="#如何构造属于自己decision-tree" class="headerlink" title="如何构造属于自己decision tree"></a>如何构造属于自己decision tree</h2><p>比如ID3 算法</p>
<p>（1） 收集数据</p>
<p>（2） 准备数据</p>
<p>（3）分析数据</p>
<p>（4）训练算法</p>
<p>（5）测试算法</p>
<p>（6）使用算法</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/04/18/example/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Author">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/04/18/example/" class="post-title-link" itemprop="url">supervised learning</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-04-18 18:29:14" itemprop="dateCreated datePublished" datetime="2020-04-18T18:29:14+01:00">2020-04-18</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-04-30 20:04:15" itemprop="dateModified" datetime="2020-04-30T20:04:15+01:00">2020-04-30</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="simple-supervised-learning-algorithms"><a href="#simple-supervised-learning-algorithms" class="headerlink" title="simple supervised learning algorithms"></a>simple supervised learning algorithms</h1><p>我们处理的主要是discrete 和 continuous. continuous 主要是linear regression， 而discrete主要是classify。 </p>
<h2 id="k-Nearest-Neighbour"><a href="#k-Nearest-Neighbour" class="headerlink" title="k-Nearest Neighbour"></a>k-Nearest Neighbour</h2><p>K-nearest neighbour 描述一种场景，假设你已经classify出了属于两个label的point，现在有一个新加入的points，那么你要如何能够判定这个point是属于哪一个label呢（投票的观点）而且 kNN 对training set 的类别比如符合高斯分布于要求。，为什么classify并不需要训练集label，这是因为本身具有的训练和validation属性就使得它在不停地矫正。</p>
<p><img src="C:\Users\32027\AppData\Roaming\Typora\typora-user-images\image-20200418184044698.png" alt="image-20200418184044698" style="zoom:67%;" /></p>
<p>如上图所示，绿色部分就是新加入的点</p>
<h3 id="what-is-k-Nearest-neighbour-learning"><a href="#what-is-k-Nearest-neighbour-learning" class="headerlink" title="what is k-Nearest neighbour learning"></a>what is k-Nearest neighbour learning</h3><p>类别： KNN 基于instance based learning， 没有显性的学习的过程，没有训练阶段，数据集实现已经有了分类和特征值，收到新的样本直接进行处理</p>
<p>步骤 </p>
<ol>
<li><p>given an unclassified pattern x find the closest k labelled patterns in the training data.也就说它会对周边的k个数据的距离进行排序。</p>
<p>如何选择distance： Euclidean distance， minimum distance</p>
</li>
</ol>
<ol>
<li>then classify as the majority 选择k邻居中最多的类别作为自己的类别，比如它的周边80%是a，那么它可能会选择a作为自己的类别</li>
</ol>
<ol>
<li>you can also weight by distance </li>
</ol>
<p>算法步骤：</p>
<ol>
<li>载入数据</li>
<li>分清楚test data和train data 的范围</li>
<li>设定k的数值，以及正式设置K neighbors 问题在于载入的X，y究竟是什么，X数数据类型吗是 Y 是classify正确和错误吗</li>
<li>预测， 通过 model.predict(Xtr or Xtra)来得到最终值</li>
</ol>
<h3 id="overfitting-and-underfitting"><a href="#overfitting-and-underfitting" class="headerlink" title="overfitting and underfitting"></a>overfitting and underfitting</h3><p>overfitting : k=过小的值比如1，过拟合，拟合程度100%， 只会匹配最近的邻居。 这种情况下一旦周边是噪音就会出现偏差</p>
<p>underfitting: k=100, waste of time ，欠拟合，尽管训练的误差值会减少，但是学习的误差值就会增大，实际的与此确不会有问题</p>
<h3 id="how-to-find-K"><a href="#how-to-find-K" class="headerlink" title="how to find K"></a>how to find K</h3><p>将数据分成training set（选取的K）and validation set（所有？）。 取trade-off的看值</p>
<h3 id="K-NN-regression"><a href="#K-NN-regression" class="headerlink" title="K-NN regression"></a>K-NN regression</h3><p>knn regression 与k nearest neighbour 的区别再去，KNN regression 是numerical value。 </p>
<p>所谓的KNN-regression 的核心思想是对于一组按照一定顺序储存的数据，我们确定这个点的值得方法可以使通过他的neighbours 来确定，。如图下</p>
<p><img src="C:\Users\32027\AppData\Roaming\Typora\typora-user-images\image-20200418210246701.png" alt="image-20200418210246701"></p>
<p>对于中心得红点，它的值可以通过周围的的K个蓝点的平均值（通常）来确定，如果我们将所有的预测点相连，那么最后我们剩下的就是一个line，当然这条line并不clean，它有时上，有时下。尽管对于线性的regression，这种方法看起来很不好，但是对于非线性的来说，这种方法非常好用</p>
<p>步骤</p>
<ol>
<li><p>对于$\vec x$ 来说，找到它最近的在training set 里的k个 input vectors</p>
</li>
<li><p>假设这些vector$\vec x_1 $ $\vec x_2$ ….. 都有对应的y值</p>
</li>
<li><p>采用uniform weight 方法，或者distance weight 方法</p>
<ul>
<li><p>uniform weight</p>
<p>$f(\vec x)={\sum^k_{i=1}y_i\over k}$</p>
</li>
</ul>
</li>
</ol>
<ul>
<li><p>distance weight (??)</p>
<p>$f(\vec x)={\sum^k_{i=1}w_iy_i\over W_i}$ and $w_i={1\over|\vec x-x_i|}$</p>
</li>
</ul>
<h2 id="linear-regression"><a href="#linear-regression" class="headerlink" title="linear regression"></a>linear regression</h2><p>linear assumption 的前提假设是 假设$f(x)=\sum^n_{i=1}a_ix_i+b$ $a_i$ 就是参数</p>
<p>linear regression 的核心就是通过选择参数$a_i$来减低mean squared the training set； 比如对于一个N的数来说</p>
<script type="math/tex; mode=display">
E={\sum_{(\vec x,y)}(y-\vec f(x))^2\over N}</script><p>想象这样一幅画面，根据不同a，b 就会生成不同的line，实际的点到想象的点有距离，我们要做的就是将square mean 变得最小</p>
<p>如图：</p>
<p><img src="C:\Users\32027\AppData\Roaming\Typora\typora-user-images\image-20200418213449475.png" alt="image-20200418213449475"></p>
<p>例子</p>
<p>但是如何最小，什么时候达到最小</p>
<p>假设 我们 有一个 N data  of the form (x,y) and we assume </p>
<p>$f(x)=ax+b$</p>
<p>$E={1\over N } \sum _{x,y}(y-ax-b)^2$ 很显然唯一不知道的值就是a，b</p>
<ol>
<li>下一步我们需要得到平均的各个值</li>
</ol>
<p>$\bar x ={1\over N}\sum _{x,y} x=E(X)$  $\bar Y ={1\over N}\sum _{x,y} Y=E(Y)$</p>
<p>$\bar {x^2 }={1\over N}\sum _{x,y} x^2=E(X^2)$</p>
<p>$\bar {Y^2 }={1\over N}\sum _{x,y} Y^2=E(Y^2)$</p>
<p>$\bar {xy }={1\over N}\sum _{x,y} xy=E(xy)$</p>
<ol>
<li><p>derivatives 如果我们想要找到最小值那么就要让</p>
<p>$\alpha E \over \alpha a$ and $\alpha E \over \alpha b$ =0</p>
<p>那么 ${\alpha E \over \alpha a}=0={1\over N } \sum_{x,y} 2(y-ax-b)(-x)$ and ${\alpha E \over \alpha b}=0={1\over N } \sum_{x,y} 2(y-ax-b)(-1)$</p>
<p>$==&gt; b=\bar y - a\bar x  $</p>
<p> ${\alpha E \over \alpha a}=0={1\over N } \sum_{x,y} 2(y-ax-b)(-x)$ ==&gt; $a\bar {x^2 }+b\bar x -\bar{xy}$ 把b带进去==&gt; a= $\bar {xy}-\bar x*\bar y\over \bar {x^2} -\bar x^2 $</p>
</li>
</ol>
<ol>
<li><img src="C:\Users\32027\AppData\Roaming\Typora\typora-user-images\image-20200418220027317.png" alt=""></li>
</ol>
<p>i is particular train pattern, the training pattern can contains many data. 举个例子，比如我们判断一个人漂不漂亮，1个pattern可能是五官，五官好的数据可以有很多个，一个pattern可能是骨架，骨架的数据又可以有很多。我们可以把这些数据视为一个整体vector 那么每一个组成。 其中$y_1=a_{1}x_{1,1}+a_2x_{1,2}….$ a作为一个整体对于所有pattern来说都是同一个，对于不同数据不一样？？</p>
<p>那么就可以得到error的式子</p>
<h3 id="parameter-optimisation"><a href="#parameter-optimisation" class="headerlink" title="parameter optimisation"></a>parameter optimisation</h3><p><img src="C:\Users\32027\AppData\Roaming\Typora\typora-user-images\image-20200419001942041.png" alt="image-20200419001942041"></p>
<h2 id="Naive-Bayes-Classifier"><a href="#Naive-Bayes-Classifier" class="headerlink" title="Naive Bayes Classifier"></a>Naive Bayes Classifier</h2><p>贝叶斯分类器是一类分类算法的统称，他们均以贝叶斯定义为基础。 </p>
<h3 id="what-is-naive-bayes-classifier"><a href="#what-is-naive-bayes-classifier" class="headerlink" title="what is naive bayes classifier"></a>what is naive bayes classifier</h3><p>朴素贝叶斯分类器在贝叶斯的基础上做出了一个最简单的假设“属性条件独立性假设”，即对于已知的类别，假设所有属性相互独立（？？是否是说各个pattern之间没有联系）每个属性独立的对分类产生影响</p>
<p>举个例子：假设某个医院收了6个问诊病人<a href="http://www.ruanyifeng.com/blog/2013/12/naive_bayes_classifier.html" target="_blank" rel="noopener">example</a> </p>
<blockquote>
<p>症状　　职业　　　疾病</p>
<p>打喷嚏　护士　　　感冒<br>打喷嚏　农夫　　　过敏<br>头痛　　建筑工人　脑震荡<br>头痛　　建筑工人　感冒<br>打喷嚏　教师　　　感冒<br>头痛　　教师　　　脑震荡</p>
</blockquote>
<p>假设现在来了第七个，它是一个打喷嚏的建筑工人，请问患上感冒的可能性有多大？这个问题可以看做是已知feature a，b 求classify 的class的类别。 </p>
<p>解决这个问题从最基本的出发就是贝叶斯定理</p>
<blockquote>
<p>P(A|B)=P(A)P(B|A)/P(B) 在B的情况下a发生的概率为多少</p>
</blockquote>
<p>那么P(感冒|建筑工人x打喷嚏)=P(感冒)P(建筑工人x打喷嚏|感冒)/P(建筑工人x打喷嚏)</p>
<p>因为朴素贝叶斯设定各个feature之间没有相关关系，所以</p>
<p>P(感冒|建筑工人x打喷嚏)=P(感冒)P(打喷嚏|感冒)*P(打喷嚏|感冒)/P(建筑工人x打喷嚏)</p>
<hr>
<p>将上面的东西公式化：</p>
<p>假设有n项features $F_1,F_2,F_3…F_n$, 我们需要将之分成m类就是$C_1,C_2,C_3…C_n$ </p>
<blockquote>
<p>$ P(C|F_1,F_2….F_3)=P(C)P(F_1|C)<em>。。。。.</em>P(F_n|C)\over P(F_1F_2F_n)$</p>
</blockquote>
<p>注意$P(F_1F_2…F_n)$ 都是一样的。所以可以忽略。问题就变成了求解$P(C)P(F_1|C)<em>。。。。.</em>P(F_n|C)$</p>
<p>这是因为我们只关心最大化</p>
<hr>
<h3 id="数据处理（）"><a href="#数据处理（）" class="headerlink" title="数据处理（）"></a>数据处理（）</h3><p><a href="https://blog.csdn.net/qq_32690999/article/details/78737393?depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-1&amp;utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-1" target="_blank" rel="noopener">cite</a></p>
<p>估计条件概率时有两种可能性1. 离散型（assignment1中）2. 连续性（assignment2）</p>
<p>对于 1 我们只需要计算每个属性取值占所有样本的数目就可以 $P(x_i |c)={|D_{c,x_i}|\over|D_C|}$</p>
<p>$D_C$ 表示训练集D第c类样本组成的集合，竖线是集合元素的数量 $D_{c,x_i}$</p>
<p>连续的情况2 可能可以使用概率密度函数，高斯函数</p>
<p>然而对于1 来说，还存在一种情况就是laplacian</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/04/13/lecture3/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Author">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/04/13/lecture3/" class="post-title-link" itemprop="url">IIS First order logic</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-04-13 14:40:20" itemprop="dateCreated datePublished" datetime="2020-04-13T14:40:20+01:00">2020-04-13</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-04-30 20:00:38" itemprop="dateModified" datetime="2020-04-30T20:00:38+01:00">2020-04-30</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="First-order-logic"><a href="#First-order-logic" class="headerlink" title="First order logic"></a>First order logic</h1><p>为什么我们需要一阶逻辑，在上一章，我们用了proposition logic，但是proposition logic 只表达事实，对于复杂的语句，proposition logic 没有办法表达，比如，有一些人是女的。这一句话就没办法表达，因此，我们引入了first order logic</p>
<h2 id="FOLs-syntax（Objects，relation，function）"><a href="#FOLs-syntax（Objects，relation，function）" class="headerlink" title="FOLs syntax（Objects，relation，function）"></a>FOLs syntax（Objects，relation，function）</h2><p>和proposition logic 相比（只包括事实），FOLs 假设这个世界包括<strong>Objects</strong>(东西)，<strong>relations</strong>（action 比如part <strong>of ，teach。 </strong>function** （关系，father of ，more than）‘. 所以FOLs 的syntax包含更多的东西。notice that the output of the function could not be a truth or false but a variable. </p>
<p>对于object来说可以是变量或者常</p>
<p>一般来说 proposition logic 由 atomic letter 和connective（连接符号） 组成。 而对于FOLs 来说，他需要 <em>constant(比如人名，地点)，predicates（关系：爸爸），variable（x，y），connectives，<em>*quantifier $\forall$ and $\exists$</em></em> . 因为在first logic 中我们会考虑的有时是个体，有时是集体。这就是为什么我们需要quantifier。</p>
<h2 id="FOLs-language"><a href="#FOLs-language" class="headerlink" title="FOLs  language"></a>FOLs  language</h2><h3 id="atomic-sentences"><a href="#atomic-sentences" class="headerlink" title="atomic sentences"></a>atomic sentences</h3><p>atomic sentence 是最基础的 fols。 它由 一个关系符号和一个在括号中的一列terms组成，这个term一般来时variable，constant，function。 就是predicate front，meaning there is relationship between terms</p>
<blockquote>
<p>Ravi and ajay are brothers =&gt; <em>Brother(Ravi,Ajay)</em></p>
<p>chinky is a cat=&gt; cat(chinky).</p>
</blockquote>
<h3 id="complex-sentence"><a href="#complex-sentence" class="headerlink" title="complex sentence"></a>complex sentence</h3><p>complex sentence 一般由基础的atomic sentence 和 connectives 组成</p>
<p>三种形式： （sentence， 一种是否定（not），一种是 autonomic sentence +connectives + autonomic sentence</p>
<blockquote>
<p>Brother(KingJohn,Richard)=&gt; Brother(Richard,KingJohn)</p>
</blockquote>
<p>很显然atomic sentence 和complex sentence能决定只是syntactically。但是他们在semantically是对的还是错的，没有办法得知。解决的方法是ground of FOLs. </p>
<h3 id="Ground-of-FOL"><a href="#Ground-of-FOL" class="headerlink" title="Ground of FOL"></a>Ground of FOL</h3><p>definition: a sentence is ground if all <strong>of its variables are replaced by constants (or instantiation).</strong> </p>
<blockquote>
<p>Teach(weiru,x)—&gt; (this step is caled grounds)teach(weiru, database) is false because wenri is not teaching database but if it is IIS. Teach(weiru,IIS). </p>
</blockquote>
<p>我们这样做的原因是因为，对于计算机来说，这些词没有意义，计算机是通过穷举的方法。来判断的，所有会有很多syntactically正确，但是在semantically是错误的句子。 我们通过g<strong>ound 来确定正误</strong></p>
<h3 id="Quantifier"><a href="#Quantifier" class="headerlink" title="Quantifier"></a>Quantifier</h3><ol>
<li><p>$\exists$ <variable><sentence></p>
<p>一些人是聪明的意味着，假设这个set中有很多个元素，$x_{1}$ $x_{2}$</p>
<p>那么就是X1 is smart or X2 is smart</p>
</li>
</ol>
<blockquote>
<p>someone at BRL is smart </p>
<p>FOL: $\exist$ x(at(x,BRL)) $\land$smart(x)</p>
</blockquote>
<p>对于$\exist$来说，它的connectives一般是$\land$ 。所以x在brl and x is smart如果用$\rightarrow$ 替代，表达的意思就会错误</p>
<blockquote>
<p>$\exist$ x(at(x,brl))=&gt; smart(x) means there is someone who is not at brl or who is smart</p>
<p>because: $\exist$ x(at(x,brl))=&gt; smart(x) is equivalent to  $\exist$ $\lnot$ x(at(x,brl)  $\lor$   smart(x) </p>
</blockquote>
<ol>
<li><p>$\forall$ <variable><sentence></p>
<p>而对于$\forall$来说，所有人是聪明的意味着，假设这个set中有很多个元素，$x_{1}$ $x_{2}$ 那么就是X1 is smart AND X2 is smart。</p>
<blockquote>
<p>everyone taking IIS is smart 只是说参加考试的smart</p>
<p>$\forall$  x(take(x,IIS)  $\implies$  smart(x)</p>
</blockquote>
<p>它的connectives是$\implies$ </p>
<p>一个常见的错误是用$\land$ </p>
<blockquote>
<p>$\forall$  x(take(x,IIS)  $\land$  smart(x) 这样意义就变成了</p>
<p>everyone takes IIS and every one is smart（这样没有参加考试的也变聪明了） </p>
</blockquote>
<ol>
<li><p>example</p>
<p>下面是一些FOLs 的例子</p>
<blockquote>
<p>all first year students in computer science take the programming module</p>
<p>$\forall$ (x) (first year(x)^(pathway(x,CS)) =&gt; takes(x,programM))</p>
</blockquote>
</li>
</ol>
</li>
</ol>
<h2 id="Knowledge-engineering-in-Fols"><a href="#Knowledge-engineering-in-Fols" class="headerlink" title="Knowledge engineering in Fols"></a>Knowledge engineering in Fols</h2><ol>
<li><p>identify the task</p>
</li>
<li><p>assemble the relevant knowledge</p>
</li>
<li><p>decide on a vocabulary of predicates,function and constants</p>
</li>
<li><p>encode general knowledge about the domain</p>
</li>
<li><p>encode a description of the specific problem instance</p>
</li>
<li><p>pose queries to the inference procedure and get answers </p>
</li>
<li><p>debug the knowledge base </p>
</li>
</ol>
<h1 id="Rule-base-system"><a href="#Rule-base-system" class="headerlink" title="Rule-base system"></a>Rule-base system</h1><h2 id="syntax-of-rules-IF-conditions-THEN-conclusion"><a href="#syntax-of-rules-IF-conditions-THEN-conclusion" class="headerlink" title="syntax of rules (IF conditions THEN conclusion)"></a>syntax of rules (IF conditions THEN conclusion)</h2><p><strong>case 1:condition and conclusion are all based on <em>propositional logics</em></strong> </p>
<p>when conditions are true for a rule, the conclusion can be inferred</p>
<p><strong>case 2 : condition and conclusion are all based on FOLs</strong> </p>
<p>we have to ground variables to figure our the IF condition in a rule is true or not</p>
<h2 id="From-English-sentence-to-FOLs-to-rules"><a href="#From-English-sentence-to-FOLs-to-rules" class="headerlink" title="From English sentence to FOLs to rules"></a>From English sentence to FOLs to rules</h2><h2 id="General-architecture"><a href="#General-architecture" class="headerlink" title="General architecture"></a>General architecture</h2><p><img src="C:\Users\32027\AppData\Roaming\Typora\typora-user-images\image-20200413220942062.png" alt="image-20200413220942062"></p>
<p>knowledge base: expert knowledge for general reasoning </p>
<p>data base： for capturing current data（dataset）</p>
<p>reasoning engine: for executing knowledge with fata to derive conclusion。 where rules are triggered when condition is true</p>
<p>explanation/feedback: to display knowledge used and explain the </p>
<p>user: to query the intelligent system for a decision support </p>
<p>complex</p>
<p><img src="C:\Users\32027\AppData\Roaming\Typora\typora-user-images\image-20200413221201344.png" alt="image-20200413221201344"></p>
<p>fusion, 是考虑来自不同来源的知识，并且给他们赋予不同权重，可能相等，可能不同然后得到新的knowledge base</p>
<p>integration 是考虑多个来源（可能相同）来移除error，duplication。换句话说，除错</p>
<h2 id="Rule-based-system-scenario"><a href="#Rule-based-system-scenario" class="headerlink" title="Rule based system  scenario"></a>Rule based system  scenario</h2><p>default logic exception: </p>
<p>$\alpha: \beta/\sigma$</p>
<h3 id="conflict"><a href="#conflict" class="headerlink" title="conflict"></a>conflict</h3><p><em>subumption</em>:conflict raises when you can drive two different conslusion when apply rules. 一种解决方法是删掉有冲突的rule。然而在很多情况不能删除。比如</p>
<blockquote>
<p>IF Age(x)&gt;18 THEN adult fare(x)</p>
<p>IF age(x)&gt;18 and student(x) then discountedfare(x)</p>
<p>问题在于当一个人又大于18岁，又是学生的时候就会出问题。简单删去rule1会使得当一个人&gt;18岁确不是学生的情况没有办法处理。解决这类问题的方式就是conflict resolution</p>
</blockquote>
<h3 id="conflict-strategy"><a href="#conflict-strategy" class="headerlink" title="conflict strategy"></a>conflict strategy</h3><p><strong>Recency：</strong>take the data which arrived in working memory fisrtly （先到先得）</p>
<p><strong>specificity:</strong>  choose the most specific one rule. the one with conditions（特殊性）</p>
<p><strong>refractories:</strong></p>
<p><em>other simple strategy</em> </p>
<hr>
<p><strong>give each rule a priority number</strong>. choose the rule with the highest number</p>
<p>Notice that: <strong>adding more rules to an existing set is dangerous</strong>. that is why </p>
<p>we can not simply integrate two set with two different algorithms tolgether </p>
<h2 id="rule-based-system-type"><a href="#rule-based-system-type" class="headerlink" title="rule based system type"></a>rule based system type</h2><p>data-driven(forward) : matching conditions with new fact</p>
<p>goal-driven(backward): which fact is more import, which one is more important. start from the top goal wand work through the sub goals </p>
<p>datadriven是基于事实的，而goal driven是基于problem。比如我们分析一个银行的贷款数据。 从data 出发，我们就会先从 这个人有钱程度，年龄来推倒一些rule。再用这些rule做判断。而对于goal driven，我们会从已知的常识中看跟problem有关的rule，再慢慢细分它有什么condition组成，组成它的condition是可知的还是不可知的。又是否可以被进一步细分。如果不可以被细分那么就舍弃，如果可以，那么也许就是rule</p>
<h3 id="uncertain-fact-and-rules"><a href="#uncertain-fact-and-rules" class="headerlink" title="uncertain fact and rules"></a>uncertain fact and rules</h3><hr>
<p>uncertainty within knowledge and facts</p>
<h2 id="inconsistency-handing"><a href="#inconsistency-handing" class="headerlink" title="inconsistency handing"></a>inconsistency handing</h2>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/04/11/human-factor-and-context/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Author">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/04/11/human-factor-and-context/" class="post-title-link" itemprop="url">human factor and context</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-04-11 13:04:37" itemprop="dateCreated datePublished" datetime="2020-04-11T13:04:37+01:00">2020-04-11</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-04-30 19:54:21" itemprop="dateModified" datetime="2020-04-30T19:54:21+01:00">2020-04-30</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/04/11/test-2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Author">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/04/11/test-2/" class="post-title-link" itemprop="url">test_2</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-04-11 13:00:43" itemprop="dateCreated datePublished" datetime="2020-04-11T13:00:43+01:00">2020-04-11</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-04-30 20:00:17" itemprop="dateModified" datetime="2020-04-30T20:00:17+01:00">2020-04-30</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

  </div>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let activeClass = CONFIG.comments.activeClass;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Author</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">19</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Author</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> v4.2.0
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">Theme – <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> v7.7.0
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      
<script type="text/x-mathjax-config">

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });

  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') {
          next = next.nextSibling;
        }
        if (next && next.nodeName.toLowerCase() === 'br') {
          next.parentNode.removeChild(next);
        }
      }
    });
  });

  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      element = document.getElementById(all[i].inputID + '-Frame').parentNode;
      if (element.nodeName.toLowerCase() == 'li') {
        element = element.parentNode;
      }
      element.classList.add('has-jax');
    }
  });
</script>
<script>
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML', () => {
    MathJax.Hub.Typeset();
  }, window.MathJax);
</script>

    

  

</body>
</html>
